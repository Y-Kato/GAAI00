"""Create & expose global retriever and LLM objects."""
from pathlib import Path
from urllib.parse import urlparse

from llama_index.core import VectorStoreIndex, StorageContext
from llama_index.vector_stores.chroma import ChromaVectorStore
from chromadb import HttpClient
from langchain.chat_models import ChatOpenAI  # å›ºå®šãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã®ã§æ—¢å­˜ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ç¶­æŒ

from config import cfg
from indexer import build_full_index

# ===== ãƒ‡ãƒãƒƒã‚°ã‚³ãƒ¼ãƒ‰ã‚’ã“ã“ã«è¿½åŠ  =====
print(f"[DEBUG] PROJECT_DIR exists: {Path(cfg.PROJECT_DIR).exists()}")
if Path(cfg.PROJECT_DIR).exists():
    files = list(Path(cfg.PROJECT_DIR).iterdir())[:5]
    print(f"[DEBUG] Files in PROJECT_DIR: {files}")
    print(f"[DEBUG] Total files: {len(list(Path(cfg.PROJECT_DIR).rglob('*')))}")
# =====================================

def _check_collection_exists_and_populated():
    """Chromaã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã—ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
    try:
        url = urlparse(cfg.CHROMA_URL)
        client = HttpClient(host=url.hostname, port=url.port)
        collection = client.get_collection(cfg.CHROMA_COLLECTION)
        count = collection.count()
        print(f"[app_context] Collection '{cfg.CHROMA_COLLECTION}' has {count} documents")
        return count > 0
    except Exception as e:
        print(f"[app_context] Collection check failed: {e}")
        return False

def _initialize_index():
    """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®åˆæœŸåŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ§‹ç¯‰ï¼‰"""
    # 1. ãƒ•ãƒ©ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ä¸¡æ–¹ã‚’ãƒã‚§ãƒƒã‚¯
    flag_exists = Path(cfg.INDEXED_FLAG_FILE).exists()
    collection_populated = _check_collection_exists_and_populated()
    
    print(f"[app_context] Flag file exists: {flag_exists}")
    print(f"[app_context] Collection populated: {collection_populated}")
    
    # 2. ã©ã¡ã‚‰ã‹ãŒæ¬ ã‘ã¦ã„ã‚‹å ´åˆã¯å†æ§‹ç¯‰
    if not flag_exists or not collection_populated:
        print("[app_context] ğŸŸ¡ Building/rebuilding full index...")
        build_full_index()
        print("[app_context] âœ… Index build completed")
    else:
        print("[app_context] âœ… Index already exists and populated")

# ---- index & retriever -------------------------------------------------
_initialize_index()

url = urlparse(cfg.CHROMA_URL)
chroma_client = HttpClient(host=url.hostname, port=url.port)
collection = chroma_client.get_or_create_collection(name=cfg.CHROMA_COLLECTION)

vector_store = ChromaVectorStore(
    chroma_collection=collection,
    collection_name=cfg.CHROMA_COLLECTION,
    persist_dir=str(cfg.CHROMA_PERSIST_DIR),
    host=url.hostname,
    port=url.port,
)
index = VectorStoreIndex.from_vector_store(vector_store)
retriever = index.as_retriever(search_kwargs={"k": 6})

# ---- LLM ---------------------------------------------------------------
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.2)

print("[app_context] ğŸ‰ Global context initialized successfully")

"""`retriever` ã¨ `llm` ã‚’ä»–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒ import ã—ã¦ä½¿ç”¨ã™ã‚‹æƒ³å®š"""